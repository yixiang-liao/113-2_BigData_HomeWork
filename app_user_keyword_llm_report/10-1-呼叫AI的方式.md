# ...existing code...
import requests
import os # To securely get the API key
from openai import OpenAI # Import the OpenAI library

# ...existing code...

# Configure the OpenAI API Key securely (e.g., using environment variables)
# Make sure to set the OPENAI_API_KEY environment variable
try:
    # It's best practice to get the key from environment variables
    OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')
    if not OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEY environment variable not set.")
    # Initialize the OpenAI client
    client = OpenAI(api_key=OPENAI_API_KEY)
except ValueError as e:
    print(f"API Key Configuration Error: {e}")
    # Handle the error appropriately, maybe return an error response
    # return JsonResponse({'error': 'API Key not configured.'}, status=500)
except Exception as e:
    print(f"An unexpected error occurred during OpenAI client initialization: {e}")
    # return JsonResponse({'error': 'Failed to initialize AI service.'}, status=500)


# ... inside api_get_userkey_report function ...
    # ... (code to get sentiment and user keyword data) ...
    # ... (code to build the prompt variable) ...

    print("--- Sending Prompt to OpenAI ---")
    print(prompt)
    print("-----------------------------")

    # Replace the Ollama call with the OpenAI API call
    try:
        # Use the chat completions endpoint (recommended for models like gpt-3.5-turbo and gpt-4)
        chat_completion = client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": system_prompt # You can use your existing system prompt
                },
                {
                    "role": "user",
                    "content": prompt # Send the combined prompt as user message
                }
            ],
            # Choose the OpenAI model you want to use
            # Examples: "gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"
            model="gpt-3.5-turbo",
            # You can add other parameters like temperature, max_tokens etc. if needed
            # temperature=0.7,
            # max_tokens=1000,
        )

        # Extract the generated text
        generated_report = chat_completion.choices[0].message.content
        print("--- OpenAI Response ---")
        print(generated_report)
        print("-----------------------")

    # It's good practice to catch specific OpenAI errors if needed
    # from openai import APIError, RateLimitError, AuthenticationError # etc.
    except Exception as e:
        print(f"Error calling OpenAI API: {e}")
        # Consider more specific error handling based on potential OpenAI API errors
        return JsonResponse({'error': f'Failed to generate report using OpenAI: {e}'}, status=500)

    # 取得AI生成的報告
    response_report = {
        'report': generated_report
        #'report': markdown.markdown(generated_report) # You can still use markdown if needed
    }

    # Combine dictionaries correctly
    # Ensure response_from_sentiment is a dictionary before merging
    if not isinstance(response_from_sentiment, dict):
         # If it's already parsed JSON, use response_data instead
         if 'response_data' in locals() and isinstance(response_data, dict):
             response_from_sentiment = response_data
         else:
             # Handle the case where sentiment data is not a dictionary
             print("Error: Sentiment data is not in the expected dictionary format.")
             # You might want to return an error or default value here
             response_from_sentiment = {} # Default to empty dict to avoid merge error


    combined_response = {**response_from_userkeyword, **response_from_sentiment, **response_report}
    return JsonResponse(combined_response)

# ...existing code...


# ...existing code...
import google.generativeai as genai
import os # To securely get the API key

# ...existing code...

# Configure the Gemini API Key securely (e.g., using environment variables)
# Make sure to set the GOOGLE_API_KEY environment variable
try:
    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')
    if not GOOGLE_API_KEY:
        raise ValueError("GOOGLE_API_KEY environment variable not set.")
    genai.configure(api_key=GOOGLE_API_KEY)
except ValueError as e:
    print(f"API Key Configuration Error: {e}")
    # Handle the error appropriately, maybe return an error response
    # return JsonResponse({'error': 'API Key not configured.'}, status=500)
except Exception as e:
    print(f"An unexpected error occurred during API configuration: {e}")
    # return JsonResponse({'error': 'Failed to configure AI service.'}, status=500)


# ... inside api_get_userkey_report function ...
    # ... (code to get sentiment and user keyword data) ...

    # print(response1_data)
    # 系統提示指令
    system_prompt = f"以下是有關於[{userkey}]的網路聲量資訊請幫我做一份至少500字的詳細的分析報告。回應時請使用繁體中文，並使用Markdown語法。\n\n"

    # 都出所有的輸入提示詞
    prompt = f'''{system_prompt}:\n\n
以下是熱門程度，有幾篇新聞報導提到它?\n\n{key_occurrence_cat}\n\n
以下是時間趨勢，這個關鍵字在過去幾天的報導數量變化:\n\n{key_time_freq}\n\n
以下是情緒分析比率，正面負面的分布情況:\n\n{sentiCount}\n\n"
以下是情緒變化的時間趨勢，在過去幾天的報導情緒正負面的篇數數量變化:\n\n{line_data_pos}\n\n{line_data_neg}\n\n"
'''
    print("--- Sending Prompt to Gemini ---")
    print(prompt)
    print("-----------------------------")


    # Call the Gemini API to generate the report
    try:
        # Choose the Gemini model you want to use (e.g., 'gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro')
        # Check the Gemini documentation for available models: https://ai.google.dev/models/gemini
        model = genai.GenerativeModel('gemini-1.5-flash') # Or 'gemini-pro', etc.

        # Generate content
        gemini_response = model.generate_content(prompt)

        # Extract the generated text
        generated_report = gemini_response.text
        print("--- Gemini Response ---")
        print(generated_report)
        print("-----------------------")

    except Exception as e:
        print(f"Error calling Gemini API: {e}")
        # Consider more specific error handling based on potential Gemini API errors
        return JsonResponse({'error': f'Failed to generate report using Gemini: {e}'}, status=500)

    # 取得AI生成的報告
    response_report = {
        'report': generated_report
        #'report': markdown.markdown(generated_report) # You can still use markdown if needed
    }

    # Combine dictionaries correctly
    # Ensure response_from_sentiment is a dictionary before merging
    if not isinstance(response_from_sentiment, dict):
         # If it's already parsed JSON, use response_data instead
         if 'response_data' in locals() and isinstance(response_data, dict):
             response_from_sentiment = response_data
         else:
             # Handle the case where sentiment data is not a dictionary
             print("Error: Sentiment data is not in the expected dictionary format.")
             # You might want to return an error or default value here
             response_from_sentiment = {} # Default to empty dict to avoid merge error


    combined_response = {**response_from_userkeyword, **response_from_sentiment, **response_report}
    return JsonResponse(combined_response)

# ...existing code...